{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62e231e",
   "metadata": {},
   "source": [
    "# Feature Selection for log_diff_model (Multivariate Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b801c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Sequential\n",
    "from bdi_predict.ml_logic.sequence_gen import WindowGenerator\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d6abab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>abs_price</th>\n",
       "      <th>log_price</th>\n",
       "      <th>log_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1995-01-03</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.293141</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-04</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.292478</td>\n",
       "      <td>-0.000664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date   Price  abs_price  log_price  log_diff\n",
       "0           0  1995-01-03  1964.0        NaN   3.293141       NaN\n",
       "1           1  1995-01-04  1961.0       -3.0   3.292478 -0.000664"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdi = pd.read_csv(\"../raw_data/data/BDI/log_diff_BDI_daily.csv\")\n",
    "bdi.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9160b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>abs_price</th>\n",
       "      <th>log_price</th>\n",
       "      <th>log_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-04</th>\n",
       "      <td>1961.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.292478</td>\n",
       "      <td>-0.000664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-05</th>\n",
       "      <td>1967.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.293804</td>\n",
       "      <td>0.001327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price  abs_price  log_price  log_diff\n",
       "Date                                              \n",
       "1995-01-04  1961.0       -3.0   3.292478 -0.000664\n",
       "1995-01-05  1967.0        6.0   3.293804  0.001327"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdi[\"Date\"] = pd.to_datetime(bdi[\"Date\"])\n",
    "bdi.set_index(\"Date\", inplace=True)\n",
    "bdi= bdi[bdi.index != \"1995-01-03\"]\n",
    "bdi.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "bdi.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd53fbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year  Value\n",
       "0    1995-01-01   7.78\n",
       "1    1995-02-01   7.47\n",
       "2    1995-03-01   7.20\n",
       "3    1995-04-01   7.06\n",
       "4    1995-05-01   6.63\n",
       "..          ...    ...\n",
       "329  2022-06-01   3.14\n",
       "330  2022-07-01   2.90\n",
       "331  2022-08-01   2.90\n",
       "332  2022-09-01   3.52\n",
       "333  2022-10-01   3.98\n",
       "\n",
       "[334 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74a953a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995-01-01</td>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995-02-01</td>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995-03-01</td>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995-04-01</td>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995-05-01</td>\n",
       "      <td>6.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2022-07-01</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>2.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>3.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>3.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>334 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Year  Value\n",
       "0    1995-01-01   7.78\n",
       "1    1995-02-01   7.47\n",
       "2    1995-03-01   7.20\n",
       "3    1995-04-01   7.06\n",
       "4    1995-05-01   6.63\n",
       "..          ...    ...\n",
       "329  2022-06-01   3.14\n",
       "330  2022-07-01   2.90\n",
       "331  2022-08-01   2.90\n",
       "332  2022-09-01   3.52\n",
       "333  2022-10-01   3.98\n",
       "\n",
       "[334 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c41e384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-02-01</th>\n",
       "      <td>7.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-03-01</th>\n",
       "      <td>7.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Value\n",
       "Date             \n",
       "1995-01-01   7.78\n",
       "1995-02-01   7.47\n",
       "1995-03-01   7.20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libor= pd.read_csv(\"../raw_data/data/LIBOR/cleaned_interest_rate.csv\")\n",
    "libor.rename(columns={\"Year\":\"Date\"}, inplace=True)\n",
    "libor[\"Date\"] = pd.to_datetime(libor[\"Date\"])\n",
    "libor.set_index(\"Date\", inplace=True)\n",
    "libor.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "751468f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_index = pd.date_range(start=\"1995-01-01\", end=\"2021-12-01\", name=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "75caa567",
   "metadata": {},
   "outputs": [],
   "source": [
    "libor_daily = pd.DataFrame(index=datetime_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3401f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>libor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-01</th>\n",
       "      <td>7.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-02</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-03</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-04</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-05</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-27</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-28</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-01</th>\n",
       "      <td>1.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9832 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            libor\n",
       "Date             \n",
       "1995-01-01   7.78\n",
       "1995-01-02    NaN\n",
       "1995-01-03    NaN\n",
       "1995-01-04    NaN\n",
       "1995-01-05    NaN\n",
       "...           ...\n",
       "2021-11-27    NaN\n",
       "2021-11-28    NaN\n",
       "2021-11-29    NaN\n",
       "2021-11-30    NaN\n",
       "2021-12-01   1.47\n",
       "\n",
       "[9832 rows x 1 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libor_daily[\"libor\"] = libor[\"Value\"]\n",
    "libor_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b23170c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9832"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libor_daily.interpolate(method=\"polynomial\", order=2, inplace=True)\n",
    "len(libor_daily)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "92316069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7065"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bca70981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>139.512036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>139.545038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-08</th>\n",
       "      <td>139.578039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-09</th>\n",
       "      <td>139.611040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-10</th>\n",
       "      <td>139.644041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08</th>\n",
       "      <td>107.030433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-09</th>\n",
       "      <td>106.747531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-10</th>\n",
       "      <td>106.464629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-11</th>\n",
       "      <td>106.181727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-14</th>\n",
       "      <td>105.898825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4192 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   GHP\n",
       "Date                  \n",
       "2007-01-04  139.512036\n",
       "2007-01-05  139.545038\n",
       "2007-01-08  139.578039\n",
       "2007-01-09  139.611040\n",
       "2007-01-10  139.644041\n",
       "...                ...\n",
       "2022-11-08  107.030433\n",
       "2022-11-09  106.747531\n",
       "2022-11-10  106.464629\n",
       "2022-11-11  106.181727\n",
       "2022-11-14  105.898825\n",
       "\n",
       "[4192 rows x 1 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = pd.read_csv(\"../raw_data/data/merged_features.csv\")\n",
    "feat[\"Date\"] = pd.to_datetime(feat[\"Date\"])\n",
    "feat.set_index(\"Date\", inplace=True)\n",
    "feat.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "feat = feat[[\"equally weighted\"]]\n",
    "feat.rename(columns={\"equally weighted\":\"GHP\"}, inplace=True)\n",
    "GHP=feat\n",
    "GHP[GHP.index > \"2007-01-03\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3a6818f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6817"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.merge(bdi, libor_daily, on=\"Date\", how=\"inner\")\n",
    "#df.drop(columns=\"Price_y\", inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e6c35d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>abs_price</th>\n",
       "      <th>log_price</th>\n",
       "      <th>log_diff</th>\n",
       "      <th>libor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-01-04</th>\n",
       "      <td>1961.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>3.292478</td>\n",
       "      <td>-0.000664</td>\n",
       "      <td>7.751225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-05</th>\n",
       "      <td>1967.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.293804</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>7.741574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-01-06</th>\n",
       "      <td>1983.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.297323</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>7.731895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Price  abs_price  log_price  log_diff     libor\n",
       "Date                                                        \n",
       "1995-01-04  1961.0       -3.0   3.292478 -0.000664  7.751225\n",
       "1995-01-05  1967.0        6.0   3.293804  0.001327  7.741574\n",
       "1995-01-06  1983.0       16.0   3.297323  0.003518  7.731895"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56980bce",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e669c6b0",
   "metadata": {},
   "source": [
    "## Holdout Method (manual, chronological)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d21fb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "2299b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df:pd.DataFrame,\n",
    "                     train_test_ratio: float,\n",
    "                     input_length: int) -> tuple:\n",
    "    '''\n",
    "    Returns a train dataframe and a test dataframe (df_train, df_test)\n",
    "    from which one can sample (X,y) sequences using TimeseriesGenerator.\n",
    "    df_train should contain all the timesteps until round(train_test_ratio * len(fold))   \n",
    "    '''\n",
    "    \n",
    "    # TRAIN SET\n",
    "\n",
    "    last_train_idx = round(train_test_ratio * len(df))\n",
    "    df_train = df.iloc[0:last_train_idx, :]\n",
    "\n",
    "    # TEST SET\n",
    " \n",
    "    first_test_idx = last_train_idx - input_length\n",
    "    df_test = df.iloc[first_test_idx:, :]\n",
    "\n",
    "    return (df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "27aaf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df=df, train_test_ratio=0.8, input_length=input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7ea39e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[[\"Price\",\"libor\"]]\n",
    "y_train = df_train[\"log_diff\"]\n",
    "\n",
    "X_test  = df_test[[\"Price\",\"libor\"]]\n",
    "y_test = df_test[\"log_diff\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "668d5c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.fit_transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c51cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TimeseriesGenerator(X_train_scaled, y_train, length=20, batch_size=16, sampling_rate=1, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7fbfa567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fe155517",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_val = TimeseriesGenerator(X_test_scaled, y_test, length=20, batch_size=16, sampling_rate=1, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "be597232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 20, 2) (16,)\n",
      "[[0.14519214 1.        ]\n",
      " [0.14571379 0.99845697]\n",
      " [0.14710485 0.99690927]\n",
      " [0.14806121 0.99223821]\n",
      " [0.14988698 0.99067186]\n",
      " [0.15023474 0.98910086]\n",
      " [0.15188663 0.98752519]\n",
      " [0.15379934 0.98594486]\n",
      " [0.15440793 0.98117589]\n",
      " [0.15475569 0.97957692]\n",
      " [0.15475569 0.97797327]\n",
      " [0.15466875 0.97636497]\n",
      " [0.1537124  0.97475201]\n",
      " [0.15240828 0.96988514]\n",
      " [0.15136498 0.96825353]\n",
      " [0.1501478  0.96661725]\n",
      " [0.14823509 0.96497632]\n",
      " [0.14710485 0.96333072]\n",
      " [0.1465832  0.95836595]\n",
      " [0.14623544 0.9567017 ]] -0.0015435717560743\n"
     ]
    }
   ],
   "source": [
    "for X, y in generator:\n",
    "    print(X.shape, y.shape)\n",
    "    print(X[0], y[0])\n",
    "    #listy = [float(X[0][i]) for i in range(len(X[0]))]\n",
    "    #print(listy)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73dff21",
   "metadata": {},
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f26bb2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler: \n",
    "\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate=1e-3,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "82b7c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizers\n",
    "\n",
    "rmsprop = RMSprop(learning_rate=lr_schedule) #or 0.001 for inital test\n",
    "adam = Adam(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "363270b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Stopping Criterion:\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_mae\", patience=100, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e5609f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing and compiling model:\n",
    "\n",
    "def init_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    #LSTM layers\n",
    "    model.add(layers.LSTM(60, activation=\"tanh\", input_shape=(20,2), return_sequences=False))\n",
    "\n",
    "    #Dense layers\n",
    "    model.add(layers.Dense(100, activation=\"relu\"))\n",
    "    model.add(layers.Dense(1, activation=\"linear\"))\n",
    "\n",
    "    #compiling model\n",
    "    model.compile(loss=\"mse\", optimizer=rmsprop, metrics=\"mae\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bfbe0",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "36345df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "742f9e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 60)                15120     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               6100      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,321\n",
      "Trainable params: 21,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Model layers & params overview:\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "051b420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "340/340 [==============================] - 2s 4ms/step - loss: 2.2678e-04 - mae: 0.0107 - val_loss: 2.2723e-04 - val_mae: 0.0128\n",
      "Epoch 2/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 1.0448e-04 - mae: 0.0076 - val_loss: 1.4034e-04 - val_mae: 0.0095\n",
      "Epoch 3/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 8.3167e-05 - mae: 0.0066 - val_loss: 9.6515e-05 - val_mae: 0.0075\n",
      "Epoch 4/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 6.7408e-05 - mae: 0.0059 - val_loss: 9.6819e-05 - val_mae: 0.0074\n",
      "Epoch 5/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 6.8237e-05 - mae: 0.0058 - val_loss: 1.0602e-04 - val_mae: 0.0079\n",
      "Epoch 6/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 6.4013e-05 - mae: 0.0055 - val_loss: 9.3938e-05 - val_mae: 0.0074\n",
      "Epoch 7/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.9248e-05 - mae: 0.0052 - val_loss: 9.1713e-05 - val_mae: 0.0074\n",
      "Epoch 8/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.9179e-05 - mae: 0.0052 - val_loss: 8.9656e-05 - val_mae: 0.0072\n",
      "Epoch 9/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7749e-05 - mae: 0.0052 - val_loss: 9.4109e-05 - val_mae: 0.0074\n",
      "Epoch 10/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 6.0433e-05 - mae: 0.0053 - val_loss: 8.9731e-05 - val_mae: 0.0071\n",
      "Epoch 11/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 6.0077e-05 - mae: 0.0052 - val_loss: 9.1733e-05 - val_mae: 0.0073\n",
      "Epoch 12/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.9513e-05 - mae: 0.0053 - val_loss: 9.0286e-05 - val_mae: 0.0072\n",
      "Epoch 13/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8482e-05 - mae: 0.0051 - val_loss: 8.9484e-05 - val_mae: 0.0072\n",
      "Epoch 14/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8315e-05 - mae: 0.0052 - val_loss: 9.8553e-05 - val_mae: 0.0076\n",
      "Epoch 15/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7937e-05 - mae: 0.0051 - val_loss: 8.9565e-05 - val_mae: 0.0071\n",
      "Epoch 16/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7771e-05 - mae: 0.0051 - val_loss: 9.1316e-05 - val_mae: 0.0072\n",
      "Epoch 17/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8040e-05 - mae: 0.0051 - val_loss: 9.0435e-05 - val_mae: 0.0072\n",
      "Epoch 18/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7781e-05 - mae: 0.0051 - val_loss: 9.0966e-05 - val_mae: 0.0073\n",
      "Epoch 19/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8316e-05 - mae: 0.0051 - val_loss: 9.2267e-05 - val_mae: 0.0073\n",
      "Epoch 20/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7892e-05 - mae: 0.0051 - val_loss: 9.0990e-05 - val_mae: 0.0073\n",
      "Epoch 21/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8213e-05 - mae: 0.0052 - val_loss: 8.9489e-05 - val_mae: 0.0072\n",
      "Epoch 22/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7368e-05 - mae: 0.0051 - val_loss: 9.5258e-05 - val_mae: 0.0075\n",
      "Epoch 23/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8046e-05 - mae: 0.0051 - val_loss: 9.3134e-05 - val_mae: 0.0074\n",
      "Epoch 24/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8020e-05 - mae: 0.0051 - val_loss: 8.9456e-05 - val_mae: 0.0071\n",
      "Epoch 25/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8384e-05 - mae: 0.0051 - val_loss: 8.9550e-05 - val_mae: 0.0072\n",
      "Epoch 26/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7807e-05 - mae: 0.0051 - val_loss: 9.4938e-05 - val_mae: 0.0075\n",
      "Epoch 27/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7195e-05 - mae: 0.0051 - val_loss: 8.9648e-05 - val_mae: 0.0071\n",
      "Epoch 28/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7817e-05 - mae: 0.0051 - val_loss: 9.0057e-05 - val_mae: 0.0072\n",
      "Epoch 29/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7422e-05 - mae: 0.0051 - val_loss: 9.1391e-05 - val_mae: 0.0073\n",
      "Epoch 30/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7653e-05 - mae: 0.0051 - val_loss: 9.1715e-05 - val_mae: 0.0072\n",
      "Epoch 31/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7185e-05 - mae: 0.0051 - val_loss: 9.0102e-05 - val_mae: 0.0072\n",
      "Epoch 32/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7942e-05 - mae: 0.0051 - val_loss: 9.0852e-05 - val_mae: 0.0073\n",
      "Epoch 33/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7462e-05 - mae: 0.0051 - val_loss: 8.9874e-05 - val_mae: 0.0072\n",
      "Epoch 34/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7252e-05 - mae: 0.0051 - val_loss: 9.1103e-05 - val_mae: 0.0073\n",
      "Epoch 35/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7693e-05 - mae: 0.0051 - val_loss: 9.1146e-05 - val_mae: 0.0072\n",
      "Epoch 36/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7790e-05 - mae: 0.0051 - val_loss: 9.3011e-05 - val_mae: 0.0074\n",
      "Epoch 37/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6706e-05 - mae: 0.0051 - val_loss: 1.0111e-04 - val_mae: 0.0078\n",
      "Epoch 38/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7875e-05 - mae: 0.0051 - val_loss: 9.1873e-05 - val_mae: 0.0073\n",
      "Epoch 39/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7501e-05 - mae: 0.0051 - val_loss: 9.2105e-05 - val_mae: 0.0072\n",
      "Epoch 40/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7302e-05 - mae: 0.0051 - val_loss: 9.3900e-05 - val_mae: 0.0073\n",
      "Epoch 41/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7839e-05 - mae: 0.0051 - val_loss: 8.9878e-05 - val_mae: 0.0072\n",
      "Epoch 42/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7783e-05 - mae: 0.0051 - val_loss: 9.1767e-05 - val_mae: 0.0073\n",
      "Epoch 43/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7264e-05 - mae: 0.0051 - val_loss: 8.9868e-05 - val_mae: 0.0072\n",
      "Epoch 44/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7356e-05 - mae: 0.0051 - val_loss: 8.9784e-05 - val_mae: 0.0072\n",
      "Epoch 45/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7089e-05 - mae: 0.0051 - val_loss: 9.1849e-05 - val_mae: 0.0073\n",
      "Epoch 46/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8058e-05 - mae: 0.0051 - val_loss: 9.3269e-05 - val_mae: 0.0072\n",
      "Epoch 47/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7733e-05 - mae: 0.0051 - val_loss: 9.4969e-05 - val_mae: 0.0075\n",
      "Epoch 48/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8059e-05 - mae: 0.0051 - val_loss: 9.0510e-05 - val_mae: 0.0072\n",
      "Epoch 49/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7482e-05 - mae: 0.0051 - val_loss: 8.9460e-05 - val_mae: 0.0071\n",
      "Epoch 50/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7779e-05 - mae: 0.0051 - val_loss: 8.9689e-05 - val_mae: 0.0072\n",
      "Epoch 51/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7795e-05 - mae: 0.0051 - val_loss: 9.4848e-05 - val_mae: 0.0073\n",
      "Epoch 52/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8361e-05 - mae: 0.0051 - val_loss: 9.1070e-05 - val_mae: 0.0071\n",
      "Epoch 53/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7305e-05 - mae: 0.0051 - val_loss: 9.6300e-05 - val_mae: 0.0074\n",
      "Epoch 54/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6565e-05 - mae: 0.0051 - val_loss: 9.0991e-05 - val_mae: 0.0073\n",
      "Epoch 55/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7475e-05 - mae: 0.0051 - val_loss: 8.9464e-05 - val_mae: 0.0071\n",
      "Epoch 56/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8082e-05 - mae: 0.0051 - val_loss: 8.9563e-05 - val_mae: 0.0071\n",
      "Epoch 57/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8054e-05 - mae: 0.0051 - val_loss: 8.9672e-05 - val_mae: 0.0071\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7425e-05 - mae: 0.0051 - val_loss: 9.4517e-05 - val_mae: 0.0075\n",
      "Epoch 59/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7327e-05 - mae: 0.0051 - val_loss: 8.9449e-05 - val_mae: 0.0071\n",
      "Epoch 60/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7277e-05 - mae: 0.0051 - val_loss: 9.0158e-05 - val_mae: 0.0072\n",
      "Epoch 61/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7667e-05 - mae: 0.0051 - val_loss: 9.0471e-05 - val_mae: 0.0072\n",
      "Epoch 62/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7910e-05 - mae: 0.0051 - val_loss: 8.9482e-05 - val_mae: 0.0071\n",
      "Epoch 63/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8307e-05 - mae: 0.0051 - val_loss: 8.9452e-05 - val_mae: 0.0071\n",
      "Epoch 64/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7817e-05 - mae: 0.0051 - val_loss: 8.9592e-05 - val_mae: 0.0071\n",
      "Epoch 65/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7391e-05 - mae: 0.0051 - val_loss: 8.9455e-05 - val_mae: 0.0071\n",
      "Epoch 66/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7360e-05 - mae: 0.0051 - val_loss: 8.9579e-05 - val_mae: 0.0072\n",
      "Epoch 67/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7683e-05 - mae: 0.0051 - val_loss: 9.2912e-05 - val_mae: 0.0072\n",
      "Epoch 68/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7584e-05 - mae: 0.0051 - val_loss: 9.3484e-05 - val_mae: 0.0074\n",
      "Epoch 69/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7590e-05 - mae: 0.0051 - val_loss: 9.0292e-05 - val_mae: 0.0072\n",
      "Epoch 70/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7407e-05 - mae: 0.0051 - val_loss: 9.0231e-05 - val_mae: 0.0071\n",
      "Epoch 71/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8206e-05 - mae: 0.0051 - val_loss: 9.4024e-05 - val_mae: 0.0074\n",
      "Epoch 72/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7655e-05 - mae: 0.0051 - val_loss: 9.3664e-05 - val_mae: 0.0074\n",
      "Epoch 73/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7597e-05 - mae: 0.0050 - val_loss: 8.9680e-05 - val_mae: 0.0071\n",
      "Epoch 74/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.8006e-05 - mae: 0.0051 - val_loss: 8.9449e-05 - val_mae: 0.0071\n",
      "Epoch 75/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7639e-05 - mae: 0.0051 - val_loss: 8.9850e-05 - val_mae: 0.0072\n",
      "Epoch 76/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7319e-05 - mae: 0.0051 - val_loss: 8.9467e-05 - val_mae: 0.0071\n",
      "Epoch 77/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7237e-05 - mae: 0.0051 - val_loss: 9.2753e-05 - val_mae: 0.0074\n",
      "Epoch 78/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7391e-05 - mae: 0.0051 - val_loss: 8.9474e-05 - val_mae: 0.0072\n",
      "Epoch 79/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7325e-05 - mae: 0.0051 - val_loss: 9.1585e-05 - val_mae: 0.0073\n",
      "Epoch 80/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7255e-05 - mae: 0.0051 - val_loss: 8.9537e-05 - val_mae: 0.0072\n",
      "Epoch 81/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7947e-05 - mae: 0.0051 - val_loss: 8.9681e-05 - val_mae: 0.0072\n",
      "Epoch 82/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7111e-05 - mae: 0.0051 - val_loss: 9.0269e-05 - val_mae: 0.0071\n",
      "Epoch 83/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7756e-05 - mae: 0.0051 - val_loss: 8.9688e-05 - val_mae: 0.0072\n",
      "Epoch 84/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7403e-05 - mae: 0.0051 - val_loss: 9.4827e-05 - val_mae: 0.0075\n",
      "Epoch 85/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7012e-05 - mae: 0.0051 - val_loss: 9.2472e-05 - val_mae: 0.0074\n",
      "Epoch 86/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7357e-05 - mae: 0.0051 - val_loss: 9.2594e-05 - val_mae: 0.0074\n",
      "Epoch 87/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7263e-05 - mae: 0.0051 - val_loss: 8.9597e-05 - val_mae: 0.0072\n",
      "Epoch 88/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7758e-05 - mae: 0.0051 - val_loss: 9.4232e-05 - val_mae: 0.0074\n",
      "Epoch 89/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7406e-05 - mae: 0.0051 - val_loss: 9.4635e-05 - val_mae: 0.0075\n",
      "Epoch 90/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7561e-05 - mae: 0.0051 - val_loss: 9.9238e-05 - val_mae: 0.0077\n",
      "Epoch 91/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7169e-05 - mae: 0.0051 - val_loss: 9.0140e-05 - val_mae: 0.0072\n",
      "Epoch 92/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7579e-05 - mae: 0.0051 - val_loss: 9.0319e-05 - val_mae: 0.0072\n",
      "Epoch 93/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7268e-05 - mae: 0.0051 - val_loss: 9.0210e-05 - val_mae: 0.0072\n",
      "Epoch 94/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7257e-05 - mae: 0.0051 - val_loss: 9.0945e-05 - val_mae: 0.0071\n",
      "Epoch 95/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7393e-05 - mae: 0.0051 - val_loss: 8.9618e-05 - val_mae: 0.0071\n",
      "Epoch 96/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7305e-05 - mae: 0.0051 - val_loss: 8.9759e-05 - val_mae: 0.0072\n",
      "Epoch 97/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7441e-05 - mae: 0.0051 - val_loss: 8.9722e-05 - val_mae: 0.0071\n",
      "Epoch 98/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7674e-05 - mae: 0.0050 - val_loss: 9.5607e-05 - val_mae: 0.0075\n",
      "Epoch 99/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7399e-05 - mae: 0.0051 - val_loss: 9.2638e-05 - val_mae: 0.0074\n",
      "Epoch 100/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7517e-05 - mae: 0.0051 - val_loss: 8.9468e-05 - val_mae: 0.0072\n",
      "Epoch 101/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7651e-05 - mae: 0.0051 - val_loss: 9.0722e-05 - val_mae: 0.0073\n",
      "Epoch 102/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7331e-05 - mae: 0.0051 - val_loss: 8.9637e-05 - val_mae: 0.0072\n",
      "Epoch 103/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6610e-05 - mae: 0.0051 - val_loss: 9.1348e-05 - val_mae: 0.0072\n",
      "Epoch 104/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6849e-05 - mae: 0.0051 - val_loss: 8.9451e-05 - val_mae: 0.0071\n",
      "Epoch 105/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6889e-05 - mae: 0.0051 - val_loss: 9.0675e-05 - val_mae: 0.0072\n",
      "Epoch 106/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7181e-05 - mae: 0.0051 - val_loss: 8.9582e-05 - val_mae: 0.0072\n",
      "Epoch 107/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7059e-05 - mae: 0.0050 - val_loss: 9.0043e-05 - val_mae: 0.0072\n",
      "Epoch 108/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7431e-05 - mae: 0.0050 - val_loss: 9.0267e-05 - val_mae: 0.0072\n",
      "Epoch 109/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7533e-05 - mae: 0.0051 - val_loss: 8.9520e-05 - val_mae: 0.0072\n",
      "Epoch 110/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7463e-05 - mae: 0.0051 - val_loss: 8.9532e-05 - val_mae: 0.0072\n",
      "Epoch 111/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7175e-05 - mae: 0.0051 - val_loss: 1.0114e-04 - val_mae: 0.0078\n",
      "Epoch 112/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7336e-05 - mae: 0.0051 - val_loss: 8.9559e-05 - val_mae: 0.0071\n",
      "Epoch 113/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7178e-05 - mae: 0.0050 - val_loss: 8.9556e-05 - val_mae: 0.0071\n",
      "Epoch 114/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7583e-05 - mae: 0.0051 - val_loss: 9.0260e-05 - val_mae: 0.0072\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7063e-05 - mae: 0.0051 - val_loss: 8.9457e-05 - val_mae: 0.0071\n",
      "Epoch 116/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7376e-05 - mae: 0.0051 - val_loss: 9.5698e-05 - val_mae: 0.0074\n",
      "Epoch 117/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7340e-05 - mae: 0.0051 - val_loss: 8.9616e-05 - val_mae: 0.0071\n",
      "Epoch 118/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6989e-05 - mae: 0.0050 - val_loss: 9.0779e-05 - val_mae: 0.0073\n",
      "Epoch 119/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7687e-05 - mae: 0.0051 - val_loss: 9.2481e-05 - val_mae: 0.0074\n",
      "Epoch 120/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7198e-05 - mae: 0.0051 - val_loss: 9.0685e-05 - val_mae: 0.0072\n",
      "Epoch 121/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7458e-05 - mae: 0.0051 - val_loss: 8.9901e-05 - val_mae: 0.0072\n",
      "Epoch 122/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7399e-05 - mae: 0.0050 - val_loss: 9.3436e-05 - val_mae: 0.0072\n",
      "Epoch 123/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7198e-05 - mae: 0.0051 - val_loss: 8.9573e-05 - val_mae: 0.0072\n",
      "Epoch 124/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7518e-05 - mae: 0.0051 - val_loss: 9.0683e-05 - val_mae: 0.0072\n",
      "Epoch 125/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7730e-05 - mae: 0.0051 - val_loss: 9.1750e-05 - val_mae: 0.0073\n",
      "Epoch 126/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7554e-05 - mae: 0.0051 - val_loss: 8.9454e-05 - val_mae: 0.0071\n",
      "Epoch 127/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7119e-05 - mae: 0.0051 - val_loss: 9.0742e-05 - val_mae: 0.0073\n",
      "Epoch 128/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7565e-05 - mae: 0.0050 - val_loss: 8.9505e-05 - val_mae: 0.0072\n",
      "Epoch 129/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7367e-05 - mae: 0.0051 - val_loss: 9.2707e-05 - val_mae: 0.0074\n",
      "Epoch 130/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7322e-05 - mae: 0.0051 - val_loss: 9.0558e-05 - val_mae: 0.0072\n",
      "Epoch 131/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7016e-05 - mae: 0.0051 - val_loss: 9.0982e-05 - val_mae: 0.0071\n",
      "Epoch 132/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6992e-05 - mae: 0.0051 - val_loss: 9.0722e-05 - val_mae: 0.0073\n",
      "Epoch 133/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7377e-05 - mae: 0.0050 - val_loss: 9.3327e-05 - val_mae: 0.0074\n",
      "Epoch 134/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7424e-05 - mae: 0.0051 - val_loss: 9.0303e-05 - val_mae: 0.0072\n",
      "Epoch 135/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7378e-05 - mae: 0.0051 - val_loss: 8.9458e-05 - val_mae: 0.0071\n",
      "Epoch 136/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6628e-05 - mae: 0.0051 - val_loss: 8.9914e-05 - val_mae: 0.0071\n",
      "Epoch 137/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7372e-05 - mae: 0.0051 - val_loss: 9.0729e-05 - val_mae: 0.0073\n",
      "Epoch 138/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7132e-05 - mae: 0.0050 - val_loss: 9.1826e-05 - val_mae: 0.0073\n",
      "Epoch 139/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7379e-05 - mae: 0.0050 - val_loss: 8.9528e-05 - val_mae: 0.0071\n",
      "Epoch 140/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7438e-05 - mae: 0.0051 - val_loss: 9.0319e-05 - val_mae: 0.0072\n",
      "Epoch 141/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7020e-05 - mae: 0.0050 - val_loss: 8.9631e-05 - val_mae: 0.0071\n",
      "Epoch 142/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7048e-05 - mae: 0.0050 - val_loss: 9.0846e-05 - val_mae: 0.0073\n",
      "Epoch 143/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6730e-05 - mae: 0.0050 - val_loss: 8.9984e-05 - val_mae: 0.0071\n",
      "Epoch 144/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6962e-05 - mae: 0.0051 - val_loss: 9.0833e-05 - val_mae: 0.0073\n",
      "Epoch 145/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7186e-05 - mae: 0.0050 - val_loss: 8.9564e-05 - val_mae: 0.0072\n",
      "Epoch 146/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6853e-05 - mae: 0.0051 - val_loss: 8.9451e-05 - val_mae: 0.0071\n",
      "Epoch 147/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6935e-05 - mae: 0.0051 - val_loss: 8.9999e-05 - val_mae: 0.0071\n",
      "Epoch 148/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7261e-05 - mae: 0.0051 - val_loss: 9.4429e-05 - val_mae: 0.0075\n",
      "Epoch 149/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6716e-05 - mae: 0.0050 - val_loss: 9.0910e-05 - val_mae: 0.0073\n",
      "Epoch 150/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7178e-05 - mae: 0.0051 - val_loss: 8.9883e-05 - val_mae: 0.0071\n",
      "Epoch 151/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7362e-05 - mae: 0.0051 - val_loss: 8.9829e-05 - val_mae: 0.0072\n",
      "Epoch 152/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6801e-05 - mae: 0.0050 - val_loss: 9.1597e-05 - val_mae: 0.0072\n",
      "Epoch 153/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7443e-05 - mae: 0.0051 - val_loss: 8.9450e-05 - val_mae: 0.0071\n",
      "Epoch 154/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7035e-05 - mae: 0.0051 - val_loss: 9.1311e-05 - val_mae: 0.0073\n",
      "Epoch 155/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6979e-05 - mae: 0.0051 - val_loss: 8.9673e-05 - val_mae: 0.0072\n",
      "Epoch 156/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7304e-05 - mae: 0.0051 - val_loss: 8.9573e-05 - val_mae: 0.0072\n",
      "Epoch 157/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7154e-05 - mae: 0.0051 - val_loss: 8.9530e-05 - val_mae: 0.0071\n",
      "Epoch 158/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6872e-05 - mae: 0.0051 - val_loss: 9.0350e-05 - val_mae: 0.0071\n",
      "Epoch 159/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6571e-05 - mae: 0.0050 - val_loss: 9.0622e-05 - val_mae: 0.0072\n",
      "Epoch 160/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6199e-05 - mae: 0.0050 - val_loss: 9.1771e-05 - val_mae: 0.0073\n",
      "Epoch 161/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7177e-05 - mae: 0.0051 - val_loss: 8.9449e-05 - val_mae: 0.0071\n",
      "Epoch 162/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7062e-05 - mae: 0.0051 - val_loss: 8.9523e-05 - val_mae: 0.0072\n",
      "Epoch 163/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6885e-05 - mae: 0.0050 - val_loss: 8.9457e-05 - val_mae: 0.0071\n",
      "Epoch 164/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7446e-05 - mae: 0.0050 - val_loss: 8.9686e-05 - val_mae: 0.0072\n",
      "Epoch 165/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7083e-05 - mae: 0.0050 - val_loss: 8.9539e-05 - val_mae: 0.0071\n",
      "Epoch 166/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7308e-05 - mae: 0.0051 - val_loss: 8.9616e-05 - val_mae: 0.0072\n",
      "Epoch 167/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6953e-05 - mae: 0.0050 - val_loss: 8.9782e-05 - val_mae: 0.0071\n",
      "Epoch 168/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6720e-05 - mae: 0.0051 - val_loss: 9.0654e-05 - val_mae: 0.0071\n",
      "Epoch 169/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6928e-05 - mae: 0.0050 - val_loss: 9.0015e-05 - val_mae: 0.0071\n",
      "Epoch 170/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6760e-05 - mae: 0.0050 - val_loss: 9.1743e-05 - val_mae: 0.0073\n",
      "Epoch 171/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6507e-05 - mae: 0.0051 - val_loss: 9.2517e-05 - val_mae: 0.0072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6507e-05 - mae: 0.0050 - val_loss: 9.1712e-05 - val_mae: 0.0072\n",
      "Epoch 173/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7132e-05 - mae: 0.0051 - val_loss: 9.0676e-05 - val_mae: 0.0072\n",
      "Epoch 174/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6544e-05 - mae: 0.0050 - val_loss: 9.0691e-05 - val_mae: 0.0072\n",
      "Epoch 175/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6939e-05 - mae: 0.0050 - val_loss: 9.1533e-05 - val_mae: 0.0073\n",
      "Epoch 176/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6681e-05 - mae: 0.0050 - val_loss: 9.1149e-05 - val_mae: 0.0073\n",
      "Epoch 177/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6821e-05 - mae: 0.0051 - val_loss: 8.9460e-05 - val_mae: 0.0071\n",
      "Epoch 178/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6693e-05 - mae: 0.0051 - val_loss: 8.9838e-05 - val_mae: 0.0071\n",
      "Epoch 179/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6976e-05 - mae: 0.0051 - val_loss: 9.0755e-05 - val_mae: 0.0073\n",
      "Epoch 180/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7158e-05 - mae: 0.0050 - val_loss: 8.9456e-05 - val_mae: 0.0071\n",
      "Epoch 181/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6876e-05 - mae: 0.0050 - val_loss: 9.0919e-05 - val_mae: 0.0073\n",
      "Epoch 182/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7024e-05 - mae: 0.0050 - val_loss: 8.9798e-05 - val_mae: 0.0071\n",
      "Epoch 183/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7103e-05 - mae: 0.0050 - val_loss: 8.9703e-05 - val_mae: 0.0072\n",
      "Epoch 184/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7427e-05 - mae: 0.0051 - val_loss: 8.9520e-05 - val_mae: 0.0072\n",
      "Epoch 185/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6562e-05 - mae: 0.0050 - val_loss: 9.4195e-05 - val_mae: 0.0074\n",
      "Epoch 186/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7064e-05 - mae: 0.0051 - val_loss: 8.9685e-05 - val_mae: 0.0071\n",
      "Epoch 187/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6737e-05 - mae: 0.0051 - val_loss: 8.9824e-05 - val_mae: 0.0072\n",
      "Epoch 188/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6842e-05 - mae: 0.0050 - val_loss: 9.0906e-05 - val_mae: 0.0073\n",
      "Epoch 189/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7200e-05 - mae: 0.0051 - val_loss: 9.1877e-05 - val_mae: 0.0073\n",
      "Epoch 190/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6972e-05 - mae: 0.0050 - val_loss: 9.2184e-05 - val_mae: 0.0072\n",
      "Epoch 191/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7038e-05 - mae: 0.0050 - val_loss: 8.9635e-05 - val_mae: 0.0072\n",
      "Epoch 192/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7300e-05 - mae: 0.0050 - val_loss: 8.9451e-05 - val_mae: 0.0071\n",
      "Epoch 193/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6858e-05 - mae: 0.0051 - val_loss: 8.9543e-05 - val_mae: 0.0072\n",
      "Epoch 194/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6824e-05 - mae: 0.0050 - val_loss: 9.9143e-05 - val_mae: 0.0077\n",
      "Epoch 195/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7603e-05 - mae: 0.0051 - val_loss: 8.9449e-05 - val_mae: 0.0071\n",
      "Epoch 196/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6323e-05 - mae: 0.0051 - val_loss: 9.0036e-05 - val_mae: 0.0072\n",
      "Epoch 197/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6835e-05 - mae: 0.0051 - val_loss: 9.0231e-05 - val_mae: 0.0072\n",
      "Epoch 198/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6700e-05 - mae: 0.0050 - val_loss: 9.1630e-05 - val_mae: 0.0073\n",
      "Epoch 199/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6522e-05 - mae: 0.0050 - val_loss: 9.1895e-05 - val_mae: 0.0072\n",
      "Epoch 200/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6941e-05 - mae: 0.0050 - val_loss: 9.2525e-05 - val_mae: 0.0074\n",
      "Epoch 201/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6707e-05 - mae: 0.0050 - val_loss: 8.9737e-05 - val_mae: 0.0071\n",
      "Epoch 202/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6622e-05 - mae: 0.0050 - val_loss: 9.1414e-05 - val_mae: 0.0073\n",
      "Epoch 203/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6543e-05 - mae: 0.0050 - val_loss: 8.9623e-05 - val_mae: 0.0072\n",
      "Epoch 204/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6796e-05 - mae: 0.0050 - val_loss: 8.9614e-05 - val_mae: 0.0071\n",
      "Epoch 205/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6342e-05 - mae: 0.0050 - val_loss: 9.2748e-05 - val_mae: 0.0072\n",
      "Epoch 206/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7086e-05 - mae: 0.0050 - val_loss: 8.9452e-05 - val_mae: 0.0071\n",
      "Epoch 207/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6912e-05 - mae: 0.0051 - val_loss: 9.0901e-05 - val_mae: 0.0073\n",
      "Epoch 208/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7059e-05 - mae: 0.0050 - val_loss: 9.1037e-05 - val_mae: 0.0073\n",
      "Epoch 209/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6812e-05 - mae: 0.0050 - val_loss: 8.9459e-05 - val_mae: 0.0071\n",
      "Epoch 210/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7172e-05 - mae: 0.0050 - val_loss: 8.9475e-05 - val_mae: 0.0071\n",
      "Epoch 211/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7315e-05 - mae: 0.0050 - val_loss: 8.9483e-05 - val_mae: 0.0072\n",
      "Epoch 212/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7172e-05 - mae: 0.0050 - val_loss: 8.9643e-05 - val_mae: 0.0071\n",
      "Epoch 213/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6563e-05 - mae: 0.0050 - val_loss: 9.1293e-05 - val_mae: 0.0073\n",
      "Epoch 214/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6311e-05 - mae: 0.0050 - val_loss: 8.9450e-05 - val_mae: 0.0071\n",
      "Epoch 215/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6500e-05 - mae: 0.0050 - val_loss: 9.0052e-05 - val_mae: 0.0071\n",
      "Epoch 216/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7053e-05 - mae: 0.0050 - val_loss: 9.2074e-05 - val_mae: 0.0073\n",
      "Epoch 217/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6548e-05 - mae: 0.0050 - val_loss: 9.3739e-05 - val_mae: 0.0073\n",
      "Epoch 218/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6764e-05 - mae: 0.0050 - val_loss: 9.2916e-05 - val_mae: 0.0072\n",
      "Epoch 219/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.7040e-05 - mae: 0.0050 - val_loss: 8.9599e-05 - val_mae: 0.0071\n",
      "Epoch 220/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6485e-05 - mae: 0.0050 - val_loss: 9.2998e-05 - val_mae: 0.0074\n",
      "Epoch 221/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6465e-05 - mae: 0.0050 - val_loss: 9.1811e-05 - val_mae: 0.0073\n",
      "Epoch 222/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6790e-05 - mae: 0.0051 - val_loss: 8.9804e-05 - val_mae: 0.0072\n",
      "Epoch 223/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6973e-05 - mae: 0.0051 - val_loss: 8.9593e-05 - val_mae: 0.0072\n",
      "Epoch 224/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6802e-05 - mae: 0.0050 - val_loss: 8.9844e-05 - val_mae: 0.0072\n",
      "Epoch 225/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6758e-05 - mae: 0.0050 - val_loss: 9.2825e-05 - val_mae: 0.0074\n",
      "Epoch 226/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6763e-05 - mae: 0.0050 - val_loss: 9.0109e-05 - val_mae: 0.0071\n",
      "Epoch 227/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6582e-05 - mae: 0.0051 - val_loss: 8.9939e-05 - val_mae: 0.0072\n",
      "Epoch 228/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6369e-05 - mae: 0.0050 - val_loss: 9.1595e-05 - val_mae: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6782e-05 - mae: 0.0050 - val_loss: 8.9566e-05 - val_mae: 0.0072\n",
      "Epoch 230/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6772e-05 - mae: 0.0050 - val_loss: 8.9454e-05 - val_mae: 0.0071\n",
      "Epoch 231/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6617e-05 - mae: 0.0050 - val_loss: 8.9572e-05 - val_mae: 0.0072\n",
      "Epoch 232/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6583e-05 - mae: 0.0050 - val_loss: 8.9763e-05 - val_mae: 0.0071\n",
      "Epoch 233/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6707e-05 - mae: 0.0050 - val_loss: 9.1841e-05 - val_mae: 0.0073\n",
      "Epoch 234/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6861e-05 - mae: 0.0050 - val_loss: 8.9466e-05 - val_mae: 0.0071\n",
      "Epoch 235/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6514e-05 - mae: 0.0050 - val_loss: 9.2829e-05 - val_mae: 0.0074\n",
      "Epoch 236/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6529e-05 - mae: 0.0050 - val_loss: 9.0439e-05 - val_mae: 0.0072\n",
      "Epoch 237/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6872e-05 - mae: 0.0050 - val_loss: 8.9514e-05 - val_mae: 0.0072\n",
      "Epoch 238/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6954e-05 - mae: 0.0050 - val_loss: 9.1532e-05 - val_mae: 0.0072\n",
      "Epoch 239/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6762e-05 - mae: 0.0050 - val_loss: 9.2028e-05 - val_mae: 0.0073\n",
      "Epoch 240/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6651e-05 - mae: 0.0050 - val_loss: 8.9591e-05 - val_mae: 0.0072\n",
      "Epoch 241/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6641e-05 - mae: 0.0050 - val_loss: 9.3562e-05 - val_mae: 0.0074\n",
      "Epoch 242/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6236e-05 - mae: 0.0050 - val_loss: 9.0428e-05 - val_mae: 0.0072\n",
      "Epoch 243/1000\n",
      "340/340 [==============================] - 1s 2ms/step - loss: 5.6849e-05 - mae: 0.0050 - val_loss: 9.0052e-05 - val_mae: 0.0072\n",
      "Epoch 244/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6666e-05 - mae: 0.0050 - val_loss: 8.9505e-05 - val_mae: 0.0072\n",
      "Epoch 245/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7034e-05 - mae: 0.0050 - val_loss: 8.9656e-05 - val_mae: 0.0072\n",
      "Epoch 246/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6671e-05 - mae: 0.0050 - val_loss: 9.0977e-05 - val_mae: 0.0073\n",
      "Epoch 247/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6748e-05 - mae: 0.0050 - val_loss: 9.1206e-05 - val_mae: 0.0073\n",
      "Epoch 248/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6768e-05 - mae: 0.0050 - val_loss: 9.0403e-05 - val_mae: 0.0072\n",
      "Epoch 249/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6829e-05 - mae: 0.0050 - val_loss: 9.0005e-05 - val_mae: 0.0072\n",
      "Epoch 250/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6708e-05 - mae: 0.0050 - val_loss: 9.0160e-05 - val_mae: 0.0072\n",
      "Epoch 251/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6933e-05 - mae: 0.0050 - val_loss: 8.9772e-05 - val_mae: 0.0072\n",
      "Epoch 252/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6214e-05 - mae: 0.0050 - val_loss: 9.1085e-05 - val_mae: 0.0073\n",
      "Epoch 253/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6663e-05 - mae: 0.0050 - val_loss: 8.9449e-05 - val_mae: 0.0071\n",
      "Epoch 254/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6368e-05 - mae: 0.0050 - val_loss: 8.9575e-05 - val_mae: 0.0072\n",
      "Epoch 255/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.5918e-05 - mae: 0.0050 - val_loss: 9.0443e-05 - val_mae: 0.0071\n",
      "Epoch 256/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6590e-05 - mae: 0.0051 - val_loss: 9.0867e-05 - val_mae: 0.0071\n",
      "Epoch 257/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6696e-05 - mae: 0.0050 - val_loss: 9.1063e-05 - val_mae: 0.0073\n",
      "Epoch 258/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6792e-05 - mae: 0.0050 - val_loss: 8.9659e-05 - val_mae: 0.0072\n",
      "Epoch 259/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6430e-05 - mae: 0.0050 - val_loss: 8.9660e-05 - val_mae: 0.0072\n",
      "Epoch 260/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6479e-05 - mae: 0.0050 - val_loss: 8.9599e-05 - val_mae: 0.0072\n",
      "Epoch 261/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6824e-05 - mae: 0.0050 - val_loss: 8.9673e-05 - val_mae: 0.0072\n",
      "Epoch 262/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6498e-05 - mae: 0.0050 - val_loss: 9.0704e-05 - val_mae: 0.0073\n",
      "Epoch 263/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6435e-05 - mae: 0.0050 - val_loss: 9.0023e-05 - val_mae: 0.0071\n",
      "Epoch 264/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6621e-05 - mae: 0.0050 - val_loss: 8.9966e-05 - val_mae: 0.0072\n",
      "Epoch 265/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6423e-05 - mae: 0.0050 - val_loss: 9.4506e-05 - val_mae: 0.0075\n",
      "Epoch 266/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7051e-05 - mae: 0.0050 - val_loss: 8.9586e-05 - val_mae: 0.0072\n",
      "Epoch 267/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6508e-05 - mae: 0.0050 - val_loss: 9.2047e-05 - val_mae: 0.0072\n",
      "Epoch 268/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6551e-05 - mae: 0.0050 - val_loss: 9.0597e-05 - val_mae: 0.0071\n",
      "Epoch 269/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.7078e-05 - mae: 0.0050 - val_loss: 9.0287e-05 - val_mae: 0.0072\n",
      "Epoch 270/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6310e-05 - mae: 0.0050 - val_loss: 8.9449e-05 - val_mae: 0.0071\n",
      "Epoch 271/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6806e-05 - mae: 0.0050 - val_loss: 9.0490e-05 - val_mae: 0.0072\n",
      "Epoch 272/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6713e-05 - mae: 0.0050 - val_loss: 9.0087e-05 - val_mae: 0.0071\n",
      "Epoch 273/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6417e-05 - mae: 0.0050 - val_loss: 9.0042e-05 - val_mae: 0.0072\n",
      "Epoch 274/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6329e-05 - mae: 0.0050 - val_loss: 9.0689e-05 - val_mae: 0.0071\n",
      "Epoch 275/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6818e-05 - mae: 0.0050 - val_loss: 9.0507e-05 - val_mae: 0.0072\n",
      "Epoch 276/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6857e-05 - mae: 0.0050 - val_loss: 8.9469e-05 - val_mae: 0.0071\n",
      "Epoch 277/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6773e-05 - mae: 0.0050 - val_loss: 8.9629e-05 - val_mae: 0.0072\n",
      "Epoch 278/1000\n",
      "340/340 [==============================] - 1s 3ms/step - loss: 5.6608e-05 - mae: 0.0050 - val_loss: 9.2224e-05 - val_mae: 0.0073\n"
     ]
    }
   ],
   "source": [
    "#TRAINING THE MODEL:\n",
    "\n",
    "history = model.fit(\n",
    "    generator, epochs=1000, validation_data=generator_val, shuffle=True, callbacks=es\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e57419",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(generator_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81dc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Curves:\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1165d165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0048812746058099115"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline MAE\n",
    "0.0048812746058099115"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7874cf9d",
   "metadata": {},
   "source": [
    "# Learning Curves viz code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5cc0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    # Loss:MSE\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('MSE')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # Metrics:MAE\n",
    "    \n",
    "    ax[1].plot(history.history['mae'])\n",
    "    ax[1].plot(history.history['val_mae'])\n",
    "    ax[1].set_title('MAE')\n",
    "    ax[1].set_ylabel('MAE')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "                        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffbd34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
